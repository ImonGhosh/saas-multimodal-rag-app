{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d106753",
   "metadata": {},
   "source": [
    "## Test Docling Image Description :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47eaade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.datamodel.pipeline_options import granite_picture_description\n",
    "from docling.datamodel.pipeline_options import smolvlm_picture_description\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.datamodel.base_models import InputFormat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4edb21ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.do_picture_description = True\n",
    "pipeline_options.picture_description_options = (\n",
    "    smolvlm_picture_description  # <-- the model choice\n",
    ")\n",
    "pipeline_options.picture_description_options.prompt = (\n",
    "    \"Describe the image in three sentences. Be consise and accurate.\"\n",
    ")\n",
    "pipeline_options.images_scale = 2.0\n",
    "pipeline_options.generate_picture_images = True\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_options=pipeline_options,\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a3eb265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] 2026-02-06 21:29:16,595 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-06 21:29:16,604 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-06 21:29:16,652 [RapidOCR] download_file.py:60: File exists and is valid: C:\\IMON\\Masters\\Self-Learning\\saas-rag-app\\my_venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-06 21:29:16,653 [RapidOCR] main.py:50: Using C:\\IMON\\Masters\\Self-Learning\\saas-rag-app\\my_venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-06 21:29:16,841 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-06 21:29:16,841 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-06 21:29:16,852 [RapidOCR] download_file.py:60: File exists and is valid: C:\\IMON\\Masters\\Self-Learning\\saas-rag-app\\my_venv\\Lib\\site-packages\\rapidocr\\models\\ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-06 21:29:16,853 [RapidOCR] main.py:50: Using C:\\IMON\\Masters\\Self-Learning\\saas-rag-app\\my_venv\\Lib\\site-packages\\rapidocr\\models\\ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-06 21:29:16,903 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-06 21:29:16,905 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-06 21:29:17,018 [RapidOCR] download_file.py:60: File exists and is valid: C:\\IMON\\Masters\\Self-Learning\\saas-rag-app\\my_venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-06 21:29:17,019 [RapidOCR] main.py:50: Using C:\\IMON\\Masters\\Self-Learning\\saas-rag-app\\my_venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.pth\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "doc = converter.convert(\"https://arxiv.org/pdf/2501.17887\").document # Doc source path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0fa808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = converter.convert(\"C:\\\\IMON\\\\Masters\\\\Self-Learning\\\\saas-rag-app\\\\api\\\\documents\\\\Seminar PPT-V2.pptx\").document # Doc source path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d4b1880",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_content = doc.export_to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "806e2338",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"C:\\\\IMON\\\\Masters\\\\Self-Learning\\\\saas-rag-app\\\\api\\\\documents\\\\presentation.md\" # Path to save markdown content\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee998e51",
   "metadata": {},
   "source": [
    "## Test Supabase Queries :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a61d8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "import asyncpg\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07d78fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "# Global database pool\n",
    "db_pool = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "943cb93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def initialize_db():\n",
    "    \"\"\"Initialize database connection pool.\"\"\"\n",
    "    global db_pool\n",
    "    if not db_pool:\n",
    "        db_pool = await asyncpg.create_pool(\n",
    "            os.getenv(\"DATABASE_URL\"),\n",
    "            min_size=2,\n",
    "            max_size=10,\n",
    "            command_timeout=60\n",
    "        )\n",
    "        logger.info(\"Database connection pool initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "639c1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "await initialize_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f34403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with db_pool.acquire() as conn:\n",
    "    results = await conn.fetch(\n",
    "        \"\"\"\n",
    "        SELECT title\n",
    "        FROM \"documents\"\n",
    "        \"\"\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbc92a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Record title='q4-2024-business-review'>,\n",
       " <Record title='14 types of RAG (Retrieval-Augmented Generation)'>,\n",
       " <Record title='Recording2'>,\n",
       " <Record title='Recording1'>,\n",
       " <Record title='Recording3'>,\n",
       " <Record title='Deep Learning for Precipitation Nowcasting'>,\n",
       " <Record title='Docling: An Efficient Open-Source Toolkit for AI-driven Document Conversion'>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "646ec07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['q4-2024-business-review',\n",
       " '14 types of RAG (Retrieval-Augmented Generation)',\n",
       " 'Recording2',\n",
       " 'Recording1',\n",
       " 'Recording3',\n",
       " 'Deep Learning for Precipitation Nowcasting',\n",
       " 'Docling: An Efficient Open-Source Toolkit for AI-driven Document Conversion']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = [r[\"title\"] for r in results if r[\"title\"] is not None]\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6902e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with db_pool.acquire() as conn:\n",
    "    results = await conn.fetch(\n",
    "        \"\"\"\n",
    "        SELECT chunk_index, content\n",
    "        FROM chunks\n",
    "        WHERE metadata->>'title' = $1\n",
    "        ORDER BY chunk_index\n",
    "        \"\"\",\n",
    "        \"Docling: An Efficient Open-Source Toolkit for AI-driven Document Conversion\",  # e.g. \"Docling: An Efficient Open-Source Toolkit for AI-driven Document Conversion\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58eca3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Record chunk_index=0 content='Docling: An Efficient Open-Source Toolkit for AI-driven Document Conversion\\nNikolaos Livathinos * , Christoph Auer * , Maksym Lysak, Ahmed Nassar, Michele Dolfi, Panagiotis Vagenas, Cesar Berrospi, Matteo Omenetti, Kasper Dinkla, Yusik Kim, Shubham Gupta, Rafael Teixeira de Lima, Valery Weber, Lucas Morin, Ingmar Meijer, Viktor Kuropiatnyk, Peter W. J. Staar\\nIBM Research, R¨ uschlikon, Switzerland\\nPlease send correspondence to: deepsearch-core@zurich.ibm.com'>,\n",
       " <Record chunk_index=1 content=\"Abstract\\nWe introduce Docling , an easy-to-use, self-contained, MITlicensed, open-source toolkit for document conversion, that can parse several types of popular document formats into a unified, richly structured representation. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. Docling is released as a Python package and can be used as a Python API or as a CLI tool. Docling's modular architecture and efficient document representation make it easy to implement extensions, new features, models, and customizations. Docling has been already integrated in other popular open-source frameworks (e.g., LangChain, LlamaIndex, spaCy), making it a natural fit for the processing of documents and the development of high-end applications. The open-source community has fully engaged in using, promoting, and developing for Docling, which gathered 10k stars on GitHub in less than a month and was reported as the No. 1 trending repository in GitHub worldwide in November 2024.\\nRepository -https://github.com/DS4SD/docling\">,\n",
       " <Record chunk_index=2 content=\"1 Introduction\\nConverting documents back into a unified machineprocessable format has been a major challenge for decades due to their huge variability in formats, weak standardization and printing-optimized characteristic, which often discards structural features and metadata. With the advent of LLMs and popular application patterns such as retrieval-augmented generation (RAG), leveraging the rich content embedded in PDFs, Office documents, and scanned document images has become ever more relevant. In the past decade, several powerful document understanding solutions have emerged on the market, most of which are commercial software, SaaS offerings on hyperscalers (Auer et al. 2022) and most recently, multimodal vision-language models. Typically, they incur a cost (e.g., for licensing or LLM inference) and cannot be run easily on local hardware. Meanwhile, only a handful of different open-source tools cover PDF, MS Word, MS PowerPoint, Images, or HTML conversion, leaving a significant feature and quality gap to proprietary solutions.\\n* These authors contributed equally.\\nCopyright © 2025, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\\nWith Docling , we recently open-sourced a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition that we developed and presented in the recent past (Livathinos et al. 2021; Pfitzmann et al. 2022; Lysak et al. 2023). Docling is designed as a simple, self-contained Python library with permissive MIT license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models. Since its launch in July 2024, Docling has attracted considerable attention in the AI developer community and ranks top on GitHub's monthly trending repositories with more than 10,000 stars at the time of writing. On October 16, 2024, Docling reached a major milestone with version 2, introducing several new features and concepts, which we outline in this updated technical report, along with details on its architecture, conversion speed benchmarks, and comparisons to other open-source assets.\\nThe following list summarizes the features currently available on Docling:\">,\n",
       " <Record chunk_index=3 content='1 Introduction\\n- Parses common document formats (PDF, Images, MS Office formats, HTML) and exports to Markdown, JSON, and HTML.\\n- Applies advanced AI for document understanding, including detailed page layout, OCR, reading order, figure extraction, and table structure recognition.\\n- Establishes a unified DoclingDocument data model for rich document representation and operations.\\n- Provides fully local execution capabilities making it suitable for sensitive data and air-gapped environments.\\n- Has an ecosystem of plug-and-play integrations with prominent generative AI development frameworks, including LangChain and LlamaIndex.\\n- Can leverage hardware accelerators such as GPUs.'>,\n",
       " <Record chunk_index=4 content=\"2 State of the Art\\nDocument conversion is a well-established field with numerous solutions already available on the market. These solutions can be categorized along several key dimensions, including open vs. closed source, permissive vs. restrictive licensing, Web APIs vs. local code deployment, susceptibility\\nFigure 1: Sketch of Docling's pipelines and usage model. Both PDF pipeline and simple pipeline build up a DoclingDocument representation, which can be further enriched. Downstream applications can utilize Docling's API to inspect, export, or chunk the document for various purposes.\\nto hallucinations, conversion quality, time-to-solution, and compute resource requirements.\\nThe most popular conversion tools today leverage visionlanguage models (VLMs), which process page images to text and markup directly. Among proprietary solutions, prominent examples include GPT-4o (OpenAI), Claude (Anthropic), and Gemini (Google). In the open-source domain, LLaVA-based models, such as LLaVA-next, are noteworthy. However, all generative AI-based models face two significant challenges. First, they are prone to hallucinations, i.e., their output may contain false information which is not present in the source document - a critical issue when faithful transcription of document content is required. Second, these models demand substantial computational resources, making the conversion process expensive. Consequently, VLM-based tools are typically offered as SaaS, with compute-intensive operations performed remotely in the cloud.\\nA second category of solutions prioritizes on-premises deployment, either as Web APIs or as libraries. Examples include Adobe Acrobat, Grobid, Marker, MinerU, Unstructured, and others. These solutions often rely on multiple specialized models, such as OCR, layout analysis, and table recognition models. Docling falls into this category, leveraging modular, task-specific models which recover document structures and features only. All text content is taken from the programmatic PDF or transcribed through OCR methods. This design ensures faithful conversion, without the risk of generating false content. However, it necessitates maintaining a diverse set of models for different document components, such as formulas or figures.\">,\n",
       " <Record chunk_index=5 content='2 State of the Art\\nWithin this category, Docling distinguishes itself through its permissive MIT license, allowing organizations to integrate Docling into their solutions without incurring licensing fees or adopting restrictive licenses (e.g., GPL). Addi- tionally, Docling offers highly accurate, resource-efficient, and fast models, making it well-suited for integration with many standard frameworks.\\nIn summary, Docling stands out as a cost-effective, accurate and transparent open-source library with a permissive license, offering a reliable and flexible solution for document conversion.'>,\n",
       " <Record chunk_index=6 content='3 Design and Architecture\\nDocling is designed in a modular fashion with extensibility in mind, and it builds on three main concepts: pipelines, parser backends, and the DoclingDocument data model as its centerpiece (see Figure 1). Pipelines and parser backends share the responsibility of constructing and enriching a DoclingDocument representation from any supported input format. The DoclingDocument data model with its APIs enable inspection, export, and downstream processing for various applications, such as RAG.'>,\n",
       " <Record chunk_index=7 content='3.1 Docling Document\\nDocling v2 introduces a unified document representation, DoclingDocument , as a Pydantic data model that can express various common document features, such as:\\n- Text, Tables, Pictures, Captions, Lists, and more.\\n- Document hierarchy with sections and groups.\\n- Disambiguation between main body and headers, footers (furniture).\\n- Layout information (i.e., bounding boxes) for all items, if available.\\n- Provenance information (i.e., page numbers, document origin).'>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00f33538",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_content = \"\\n\".join(\n",
    "    r[\"content\"] for r in sorted(results, key=lambda x: x[\"chunk_index\"])\n",
    "    if r[\"content\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10bdb57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docling: An Efficient Open-Source Toolkit for AI-driven Document Conversion\n",
      "Nikolaos Livathinos * , Christoph Auer * , Maksym Lysak, Ahmed Nassar, Michele Dolfi, Panagiotis Vagenas, Cesar Berrospi, Matteo Omenetti, Kasper Dinkla, Yusik Kim, Shubham Gupta, Rafael Teixeira de Lima, Valery Weber, Lucas Morin, Ingmar Meijer, Viktor Kuropiatnyk, Peter W. J. Staar\n",
      "IBM Research, R¨ uschlikon, Switzerland\n",
      "Please send correspondence to: deepsearch-core@zurich.ibm.com\n",
      "Abstract\n",
      "We introduce Docling , an easy-to-use, self-contained, MITlicensed, open-source toolkit for document conversion, that can parse several types of popular document formats into a unified, richly structured representation. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. Docling is released as a Python package and can be used as a Python API or as a CLI tool. Docling's modular architecture and efficient document representation make it easy to implement extensions, new features, models, and customizations. Docling has been already integrated in other popular open-source frameworks (e.g., LangChain, LlamaIndex, spaCy), making it a natural fit for the processing of documents and the development of high-end applications. The open-source community has fully engaged in using, promoting, and developing for Docling, which gathered 10k stars on GitHub in less than a month and was reported as the No. 1 trending repository in GitHub worldwide in November 2024.\n",
      "Repository -https://github.com/DS4SD/docling\n",
      "1 Introduction\n",
      "Converting documents back into a unified machineprocessable format has been a major challenge for decades due to their huge variability in formats, weak standardization and printing-optimized characteristic, which often discards structural features and metadata. With the advent of LLMs and popular application patterns such as retrieval-augmented generation (RAG), leveraging the rich content embedded in PDFs, Office documents, and scanned document images has become ever more relevant. In the past decade, several powerful document understanding solutions have emerged on the market, most of which are commercial software, SaaS offerings on hyperscalers (Auer et al. 2022) and most recently, multimodal vision-language models. Typically, they incur a cost (e.g., for licensing or LLM inference) and cannot be run easily on local hardware. Meanwhile, only a handful of different open-source tools cover PDF, MS Word, MS PowerPoint, Images, or HTML conversion, leaving a significant feature and quality gap to proprietary solutions.\n",
      "* These authors contributed equally.\n",
      "Copyright © 2025, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\n",
      "With Docling , we recently open-sourced a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition that we developed and presented in the recent past (Livathinos et al. 2021; Pfitzmann et al. 2022; Lysak et al. 2023). Docling is designed as a simple, self-contained Python library with permissive MIT license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models. Since its launch in July 2024, Docling has attracted considerable attention in the AI developer community and ranks top on GitHub's monthly trending repositories with more than 10,000 stars at the time of writing. On October 16, 2024, Docling reached a major milestone with version 2, introducing several new features and concepts, which we outline in this updated technical report, along with details on its architecture, conversion speed benchmarks, and comparisons to other open-source assets.\n",
      "The following list summarizes the features currently available on Docling:\n",
      "1 Introduction\n",
      "- Parses common document formats (PDF, Images, MS Office formats, HTML) and exports to Markdown, JSON, and HTML.\n",
      "- Applies advanced AI for document understanding, including detailed page layout, OCR, reading order, figure extraction, and table structure recognition.\n",
      "- Establishes a unified DoclingDocument data model for rich document representation and operations.\n",
      "- Provides fully local execution capabilities making it suitable for sensitive data and air-gapped environments.\n",
      "- Has an ecosystem of plug-and-play integrations with prominent generative AI development frameworks, including LangChain and LlamaIndex.\n",
      "- Can leverage hardware accelerators such as GPUs.\n",
      "2 State of the Art\n",
      "Document conversion is a well-established field with numerous solutions already available on the market. These solutions can be categorized along several key dimensions, including open vs. closed source, permissive vs. restrictive licensing, Web APIs vs. local code deployment, susceptibility\n",
      "Figure 1: Sketch of Docling's pipelines and usage model. Both PDF pipeline and simple pipeline build up a DoclingDocument representation, which can be further enriched. Downstream applications can utilize Docling's API to inspect, export, or chunk the document for various purposes.\n",
      "to hallucinations, conversion quality, time-to-solution, and compute resource requirements.\n",
      "The most popular conversion tools today leverage visionlanguage models (VLMs), which process page images to text and markup directly. Among proprietary solutions, prominent examples include GPT-4o (OpenAI), Claude (Anthropic), and Gemini (Google). In the open-source domain, LLaVA-based models, such as LLaVA-next, are noteworthy. However, all generative AI-based models face two significant challenges. First, they are prone to hallucinations, i.e., their output may contain false information which is not present in the source document - a critical issue when faithful transcription of document content is required. Second, these models demand substantial computational resources, making the conversion process expensive. Consequently, VLM-based tools are typically offered as SaaS, with compute-intensive operations performed remotely in the cloud.\n",
      "A second category of solutions prioritizes on-premises deployment, either as Web APIs or as libraries. Examples include Adobe Acrobat, Grobid, Marker, MinerU, Unstructured, and others. These solutions often rely on multiple specialized models, such as OCR, layout analysis, and table recognition models. Docling falls into this category, leveraging modular, task-specific models which recover document structures and features only. All text content is taken from the programmatic PDF or transcribed through OCR methods. This design ensures faithful conversion, without the risk of generating false content. However, it necessitates maintaining a diverse set of models for different document components, such as formulas or figures.\n",
      "2 State of the Art\n",
      "Within this category, Docling distinguishes itself through its permissive MIT license, allowing organizations to integrate Docling into their solutions without incurring licensing fees or adopting restrictive licenses (e.g., GPL). Addi- tionally, Docling offers highly accurate, resource-efficient, and fast models, making it well-suited for integration with many standard frameworks.\n",
      "In summary, Docling stands out as a cost-effective, accurate and transparent open-source library with a permissive license, offering a reliable and flexible solution for document conversion.\n",
      "3 Design and Architecture\n",
      "Docling is designed in a modular fashion with extensibility in mind, and it builds on three main concepts: pipelines, parser backends, and the DoclingDocument data model as its centerpiece (see Figure 1). Pipelines and parser backends share the responsibility of constructing and enriching a DoclingDocument representation from any supported input format. The DoclingDocument data model with its APIs enable inspection, export, and downstream processing for various applications, such as RAG.\n",
      "3.1 Docling Document\n",
      "Docling v2 introduces a unified document representation, DoclingDocument , as a Pydantic data model that can express various common document features, such as:\n",
      "- Text, Tables, Pictures, Captions, Lists, and more.\n",
      "- Document hierarchy with sections and groups.\n",
      "- Disambiguation between main body and headers, footers (furniture).\n",
      "- Layout information (i.e., bounding boxes) for all items, if available.\n",
      "- Provenance information (i.e., page numbers, document origin).\n"
     ]
    }
   ],
   "source": [
    "print(full_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b332f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with db_pool.acquire() as conn:\n",
    "    async with conn.transaction():\n",
    "        await conn.execute(\n",
    "            \"DELETE FROM chunks WHERE metadata->>'title' = $1\",\n",
    "            \"API Gateway Configuration Example gateway: host: api.neuralflow-ai.com port: 443 ssl: true rate_limit: requests_per_minute: 1000 burst: 100 auth: type: jwt token_expiry: 3600 routes: - path: /v1/documents/* service: document-processor methods: [POST, GET] - path: /v1/chat/* service: document-processor methods: [POST, GET] - path: /v1/chat/* service: conversational-ai methods: [POST, GET, DELETE]\",\n",
    "        )\n",
    "        await conn.execute(\n",
    "            \"DELETE FROM documents WHERE title = $1\",\n",
    "            \"NeuralFlow AI - Mission and Goals\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "591368e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"NeuralFlow AI - Team Handbook\",\"Boids / Flocking Algorithm\"]\n",
    "\n",
    "async with db_pool.acquire() as conn:\n",
    "    async with conn.transaction():\n",
    "        # 1) Delete all chunks whose metadata->>'title' matches any of the titles\n",
    "        await conn.execute(\n",
    "            \"\"\"\n",
    "            DELETE FROM chunks\n",
    "            WHERE metadata->>'title' = ANY($1::text[])\n",
    "            \"\"\",\n",
    "            titles,\n",
    "        )\n",
    "\n",
    "        # 2) Delete all documents whose title matches any of the titles\n",
    "        await conn.execute(\n",
    "            \"\"\"\n",
    "            DELETE FROM documents\n",
    "            WHERE title = ANY($1::text[])\n",
    "            \"\"\",\n",
    "            titles,\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
